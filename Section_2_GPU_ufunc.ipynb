{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ufuncs/gufuncs (subject of this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Universal Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has the concept of universal functions (\"ufuncs\"), which are functions that can take NumPy arrays of varying dimensions (or scalars) and operate on them element-by-element.\n",
    "\n",
    "It is probably easiest to show what happens by example. We'll use the NumPy add ufunc to demonstrate what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 22, 33, 44])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "\n",
    "np.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ufuncs also can combine scalars with arrays:m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101, 102, 103, 104])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(a, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays of different, but compatible dimensions can also be combined. The lower dimensional array will be replicated to match the dimensionality of the higher dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "b: [10. 20. 30. 40.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10., 21., 32., 43.],\n",
       "       [14., 25., 36., 47.],\n",
       "       [18., 29., 40., 51.],\n",
       "       [22., 33., 44., 55.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.arange(4*4).reshape((4,4))\n",
    "print('c:', c)\n",
    "print('b:', b )\n",
    "np.add(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above situation, the b array is added to each row of c. If we want to add b to each column, we need to transpose it. There are several ways to do this, but one way is to insert a new axis using np.newaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [20],\n",
       "       [30],\n",
       "       [40]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_col = b[:, np.newaxis]\n",
    "b_col.astype(dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 12, 13],\n",
       "       [24, 25, 26, 27],\n",
       "       [38, 39, 40, 41],\n",
       "       [52, 53, 54, 55]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(b_col, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Making ufuncs for the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba has the ability to create compiled ufuncs. You implement a scalar function of all the inputs, and Numba will figure out the broadcast rules for you. Generating a ufunc that uses CUDA requires giving an explicit type signature and setting the target attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['int32(int32, int32)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b:\n",
      " [11 22 33 44]\n",
      "\n",
      "b_col + c:\n",
      " [[10 11 12 13]\n",
      " [24 25 26 27]\n",
      " [38 39 40 41]\n",
      " [52 53 54 55]]\n"
     ]
    }
   ],
   "source": [
    "print('a+b:\\n', add_ufunc(a, b))\n",
    "print()\n",
    "print('b_col + c:\\n', add_ufunc(b_col, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of things just happened! Numba automatically:\n",
    "\n",
    "    - Compiled a CUDA kernel to execute the ufunc operation in parallel over all the input elements.\n",
    "    - Allocated GPU memory for the inputs and the output.\n",
    "    - Copied the input data to the GPU.\n",
    "    - Executed the CUDA kernel with the correct kernel dimensions given the input sizes.\n",
    "    - Copied the result back from the GPU to the CPU.\n",
    "    - Returned the result as a NumPy array on the host.\n",
    "\n",
    "This is very convenient for testing, but copying data back and forth between the CPU and GPU can be slow and hurt performance. In the next tutorial notebook, you'll learn about device management and memory allocation.\n",
    "\n",
    "You might be wondering how fast our simple example is on the GPU? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 µs ± 41.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.add(b_col, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 ms ± 269 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(b_col, c) # Numba on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, the GPU is a lot slower than the CPU?? This is to be expected because we have (deliberately) misused the GPU in several ways in this example:\n",
    "- Our inputs are too small: the GPU achieves performance through parallelism, operating on thousands of values at once. Our test inputs have only 4 and 16 integers, respectively. We need a much larger array to even keep the GPU busy.\n",
    "- Our calculation is too simple: Sending a calculation to the GPU involves quite a bit of overhead compared to calling a function on the CPU. If our calculation does not involve enough math operations (often called \"arithmetic intensity\"), then the GPU will spend most of its time waiting for data to move around.\n",
    "- We copy the data to and from the GPU: While including the copy time can be realistic for a single function, often we want to run several GPU operations in sequence. In those cases, it makes sense to send data to the GPU and keep it there until all of our processing is complete.\n",
    "- Our data types are larger than necessary: Our example uses int64 when we probably don't need it. Scalar code using data types that are 32 and 64-bit run basically the same speed on the CPU, but 64-bit data types have a significant performance cost on the GPU. Basic arithmetic on 64-bit floats can be anywhere from 2x (Pascal-architecture Tesla) to 24x (Maxwell-architecture GeForce) slower than 32-bit floats. NumPy defaults to 64-bit data types when creating arrays, so it is important to set the dtype attribute or use the ndarray.astype() method to pick 32-bit types when you need them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above, let's try an example that is faster on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00466425], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Gaussian a million times!\n",
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.3 ms ± 5.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty large improvement, even including the overhead of copying all the data to and from the GPU. Ufuncs that use special functions (exp, sin, cos, etc) on large data sets run especially well on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda') # ???\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.67 ms ± 1.36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x, y)  # Baseline performance with host arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.gpus[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numba.cuda module includes a function that will copy host data to the GPU and return a CUDA device array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x0000019F94CA24E0>\n",
      "(100000,)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "print(x_device)\n",
    "print(x_device.shape)\n",
    "print(x_device.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device arrays can be passed to CUDA functions just like NumPy arrays, but without the copy overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 ms ± 113 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x_device, y_device) # it is faster corresponding to the first case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big performance improvement already, but we are still allocating a device array for the output of the ufunc and copying it back to the host. We can create the output buffer with the numba.cuda.device_array() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 ms ± 264 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x_device, y_device, out=out_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed the device allocation and copy steps, the computation runs much faster than before. When we want to bring the device array back to the host memory, we can use the copy_to_host() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    }
   ],
   "source": [
    "out_host = out_device.copy_to_host()\n",
    "print(out_host[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def make_pulses(i, period, amplitude):\n",
    "    return max(math.sin(i / period) - 0.3, 0.0) * amplitude\n",
    "\n",
    "n = 100000\n",
    "noise = (np.random.normal(size=n) * 3).astype(np.float32)\n",
    "t = np.arange(n, dtype=np.float32)\n",
    "period = n / 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses = make_pulses(t, period, 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pulses)\n",
    "len(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = add_ufunc(pulses, noise) # It uses GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19f9679ca20>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cuda Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
    "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
    "\n",
    "    block_size = cuda.blockDim.x  # number of threads per block\n",
    "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
    "    \n",
    "    start = tx + ty * block_size\n",
    "    stride = block_size * grid_size\n",
    "    \n",
    "    print(tx.copy_to_host()) # How to print?\n",
    "    \n",
    "    # assuming x and y inputs are same length\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that we did not need to specify a type signature for the CUDA kernel. Unlike @vectorize, Numba can infer the type signature from the inputs automatically, and much more reliably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed at nopython (nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'copy_to_host' of type int32\n\u001b[1m\nFile \"<ipython-input-24-8de81d0bd0a0>\", line 12:\u001b[0m\n\u001b[1mdef add_kernel(x, y, out):\n    <source elided>\n    \n\u001b[1m    print(tx.copy_to_host()) # How to print?\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of get attribute at <ipython-input-24-8de81d0bd0a0> (12)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-24-8de81d0bd0a0>\", line 12:\u001b[0m\n\u001b[1mdef add_kernel(x, y, out):\n    <source elided>\n    \n\u001b[1m    print(tx.copy_to_host()) # How to print?\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4d9dd0deb45c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mblocks_per_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0madd_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblocks_per_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads_per_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mSpecialize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minvoke\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         '''\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mspecialize\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    745\u001b[0m         argtypes = tuple(\n\u001b[0;32m    746\u001b[0m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[1;32m--> 747\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'link'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             kernel = compile_kernel(self.py_func, argtypes,\n\u001b[1;32m--> 762\u001b[1;33m                                     **self.targetoptions)\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcore\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_cuda_compiler_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile_kernel\u001b[1;34m(pyfunc, args, link, debug, inline, fastmath, extensions)\u001b[0m\n\u001b[0;32m     74\u001b[0m def compile_kernel(pyfunc, args, link, debug=False, inline=False,\n\u001b[0;32m     75\u001b[0m                    fastmath=False, extensions=[]):\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mcres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllvm_func_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcore\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_cuda_compiler_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile_cuda\u001b[1;34m(pyfunc, return_type, args, debug, inline)\u001b[0m\n\u001b[0;32m     63\u001b[0m                                   \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                                   \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                                   locals={})\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mlibrary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    871\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    872\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m--> 873\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \"\"\"\n\u001b[0;32m    803\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_pipelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# Early pipeline completion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    251\u001b[0m                     \u001b[1;31m# No more fallback pipelines?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m                     \u001b[1;31m# Go to next fallback pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                     \u001b[0mstage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                 self.locals)\n\u001b[0m\u001b[0;32m    460\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypemap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[1;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, raise_errors)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed at nopython (nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'copy_to_host' of type int32\n\u001b[1m\nFile \"<ipython-input-24-8de81d0bd0a0>\", line 12:\u001b[0m\n\u001b[1mdef add_kernel(x, y, out):\n    <source elided>\n    \n\u001b[1m    print(tx.copy_to_host()) # How to print?\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of get attribute at <ipython-input-24-8de81d0bd0a0> (12)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-24-8de81d0bd0a0>\", line 12:\u001b[0m\n\u001b[1mdef add_kernel(x, y, out):\n    <source elided>\n    \n\u001b[1m    print(tx.copy_to_host()) # How to print?\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x\n",
    "out = np.empty_like(x)\n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 30\n",
    "\n",
    "add_kernel[blocks_per_grid, threads_per_block](x, y, out)\n",
    "print(out[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, unlike the ufunc, the arguments are passed to the kernel as full NumPy arrays. The kernel can access any element in the array it wants, regardless of its position in the thread grid. This is why CUDA kernels are significantly more powerful that ufuncs. (But with great power, comes a greater amount of typing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    start = cuda.grid(1)      # 1 = one dimensional thread grid, returns a single value\n",
    "    stride = cuda.gridsize(1) # ditto\n",
    "\n",
    "    # assuming x and y inputs are same length\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
